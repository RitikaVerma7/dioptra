{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow ImageNet-ResNet50 Patch Demo\n",
    "\n",
    "This notebook demonstrates the adversarial patch attack applied on the ResNet50 model.\n",
    "\n",
    "The following two sections cover experiment setup and is similar across all demos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Experiment Name and Fruits360 Dataset\n",
    "\n",
    "Here we will import the necessary Python modules and ensure the proper environment variables are set so that all the code blocks will work as expected.\n",
    "\n",
    "### Important: Users will need to verify or update the following parameters:\n",
    "- Ensure that the `USERNAME` parameter is set to your own name.\"\n",
    "- Ensure that the `DATASET_DIR` parameter is set to the location of the ImageNet dataset directory. Currently set to `/nfs/data/ImageNet-Kaggle-2017\"` as the default location.\n",
    "- (Optional) Set the `EXPERIMENT_NAME` parameter to your own preferred experiment name.\n",
    "\n",
    "Other parameters can be modified to alter the RESTful API and MLFlow tracking addresses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages from the Python standard library\n",
    "import os\n",
    "import pprint\n",
    "import time\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "\n",
    "# Please enter custom username here.\n",
    "USERNAME = \"howard\"\n",
    "\n",
    "# Filter out warning messages\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Ensure that the base dataset location is properly set here.\n",
    "DATASET_DIR = \"/nfs/data/ImageNet-Kaggle-2017\"\n",
    "\n",
    "# Default address for accessing the RESTful API service\n",
    "RESTAPI_ADDRESS = \"http://localhost:30080\"\n",
    "\n",
    "# Base API address\n",
    "RESTAPI_API_BASE = f\"{RESTAPI_ADDRESS}/api\"\n",
    "\n",
    "# Default address for accessing the MLFlow Tracking server\n",
    "MLFLOW_TRACKING_URI = \"http://localhost:35000\"\n",
    "\n",
    "# Path to workflows archive\n",
    "WORKFLOWS_TAR_GZ = Path(\"workflows.tar.gz\")\n",
    "\n",
    "# Experiment name (note the username_ prefix convention)\n",
    "EXPERIMENT_NAME = f\"{USERNAME}_imagenet_adversarial_patch\"\n",
    "\n",
    "# Set MLFLOW_TRACKING_URI variable, used to connect to MLFlow Tracking service\n",
    "if os.getenv(\"MLFLOW_TRACKING_URI\") is None:\n",
    "    os.environ[\"MLFLOW_TRACKING_URI\"] = MLFLOW_TRACKING_URI\n",
    "\n",
    "# Import third-party Python packages\n",
    "import numpy as np\n",
    "import requests\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# Import utils.py file\n",
    "import utils\n",
    "\n",
    "# Create random number generator\n",
    "rng = np.random.default_rng(54399264723942495723666216079516778448)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the Makefile works in your environment by executing the `bash` code block below,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mAvailable rules:\u001b[m\n",
      "\n",
      "\u001b[36mclean              \u001b[m Remove temporary files \n",
      "\u001b[36mdata               \u001b[m Download and prepare MNIST dataset \n",
      "\u001b[36minitdb             \u001b[m Initialize the RESTful API database \n",
      "\u001b[36mservices           \u001b[m Launch the Minio S3 and MLFlow Tracking services \n",
      "\u001b[36mteardown           \u001b[m Destroy service containers \n",
      "\u001b[36mworkflows          \u001b[m Create workflows tarball \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Running this will just list the available rules defined in the demo's Makefile.\n",
    "make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ImageNet dataset needed for the demo is available in all worker containers at the path `/nfs/data/ImageNet-Kaggle-2017/images/ILSVRC/Data/CLS-LOC/`.\n",
    "The following directores contain labeled JPEG images:\n",
    "\n",
    "    train  \n",
    "    val-sorted  \n",
    "    val-sorted-1000\n",
    "    val-sorted-5000\n",
    "    val-sorted-10000  \n",
    "    \n",
    "Both train and val-sorted contain a full set of labeled training and test images. val-sorted-# directories hold a random partion of labeled images, with 1000, 5000, or 10000 images in total. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   Each of the directories listed follows the general subfolder structure below:\n",
    "\n",
    "    ImageNet\n",
    "    │ \n",
    "    │ \n",
    "    ├── train\n",
    "    │   ├── {class 0 directory}\n",
    "    │   ├── {class 1 directory}\n",
    "    │   ├── ...\n",
    "    │   ├── ...\n",
    "    │   ├── ...\n",
    "    │   └── {class 999 directory}\n",
    "    │ \n",
    "    └── val-sorted\n",
    "    │ \n",
    "    │   ├── {class 0 directory}\n",
    "    │   ├── {class 1 directory}\n",
    "    │   ├── ...\n",
    "    │   ├── ...\n",
    "    │   ├── ...\n",
    "    │   └── {class 999 directory}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The subfolders under `Mnist/training/` and `Mnist/testing/` are the classification labels for the images in the dataset.\n",
    "This folder structure is a standardized way to encode the label information and many libraries can make use of it, including the Tensorflow library that we are using for this particular demo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit and run jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The jobs that we will be running are implemented in the Python source files under `src/`, which will be executed using the entrypoints defined in the `MLproject` file.\n",
    "To get this information into the architecture, we need to package those files up into an archive and upload it to the lab API.\n",
    "For convenience, the `Makefile` provides a rule for creating the archive file, just run `make workflows`,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make: Nothing to be done for 'workflows'.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Create the workflows.tar.gz file\n",
    "make workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To connect with the endpoint, we will use a client class defined in the `utils.py` file that is able to connect with the lab's RESTful API using the HTTP protocol.\n",
    "We connect using the client below,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "restapi_client = utils.SecuringAIClient(address=RESTAPI_API_BASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to register an experiment under which to collect our job runs.\n",
    "The code below checks if the relevant experiment exists.\n",
    "If it does, then it just returns info about the experiment, if it doesn't, it then registers the new experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'createdOn': '2021-01-06T20:00:36.372309',\n",
       " 'experimentId': 20,\n",
       " 'lastModified': '2021-01-06T20:00:36.372309',\n",
       " 'name': 'howard_imagenet_adversarial_patch'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_experiment = restapi_client.get_experiment_by_name(name=EXPERIMENT_NAME)\n",
    "\n",
    "if response_experiment is None or \"Not Found\" in response_experiment.get(\"message\", []):\n",
    "    response_experiment = restapi_client.register_experiment(name=EXPERIMENT_NAME)\n",
    "\n",
    "response_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following helper functions will recheck the job responses until the job is completed or a run ID is available. \n",
    "# The run ID is needed to link dependencies between jobs.\n",
    "def mlflow_run_id_is_not_known(job_response):\n",
    "    return job_response[\"mlflowRunId\"] is None and job_response[\"status\"] not in [\n",
    "        \"failed\",\n",
    "        \"finished\",\n",
    "    ]\n",
    "\n",
    "def get_run_id(job_response):\n",
    "    while mlflow_run_id_is_not_known(job_response):\n",
    "        time.sleep(1)\n",
    "        job_response = restapi_client.get_job_by_id(job_response[\"jobId\"])\n",
    "        \n",
    "    return job_response\n",
    "\n",
    "def wait_until_finished(job_response):\n",
    "    # First make sure job has started.\n",
    "    job_response = get_run_id(job_response)\n",
    "    \n",
    "    # Next re-check job until it has stopped running.\n",
    "    while (job_response[\"status\"] not in [\"failed\", \"finished\"]):\n",
    "        time.sleep(1)\n",
    "        job_response = restapi_client.get_job_by_id(job_response[\"jobId\"])\n",
    "    \n",
    "    return job_response\n",
    "\n",
    "# Helper function for viewing MLflow results.\n",
    "def get_mlflow_results(job_response):\n",
    "    mlflow_client = MlflowClient()\n",
    "    job_response = wait_until_finished(job_response)\n",
    "    \n",
    "    if(job_response['status']==\"failed\"):\n",
    "        return {}\n",
    "    \n",
    "    run = mlflow_client.get_run(job_response[\"mlflowRunId\"])  \n",
    "    \n",
    "    while(len(run.data.metrics) == 0):\n",
    "        time.sleep(1)\n",
    "        run = mlflow_client.get_run(job_response[\"mlflowRunId\"])\n",
    "        \n",
    "    return run\n",
    "\n",
    "def print_mlflow_results(response):\n",
    "    results = get_mlflow_results(response)\n",
    "    pprint.pprint(results.data.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to train our model.\n",
    "We will be using the V100 GPUs that are available on the DGX Workstation, which we can use by submitting our job to the `\"tensorflow_gpu\"` queue.\n",
    "We will train the ResNet50 model on a subset of the ImageNet dataset.,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization job for ResNet50 neural network submitted\n",
      "\n",
      "{'createdOn': '2021-02-14T21:13:14.365622',\n",
      " 'dependsOn': None,\n",
      " 'entryPoint': 'init_model',\n",
      " 'entryPointKwargs': '-P batch_size=20 -P model_architecture=resnet50 -P '\n",
      "                     'data_dir=/nfs/data/ImageNet-Kaggle-2017/images/ILSVRC/Data/CLS-LOC/val-sorted-1000',\n",
      " 'experimentId': 20,\n",
      " 'jobId': '5e30b0eb-de4c-4b5c-a949-1fe044466845',\n",
      " 'lastModified': '2021-02-14T21:13:14.365622',\n",
      " 'mlflowRunId': None,\n",
      " 'queueId': 2,\n",
      " 'status': 'queued',\n",
      " 'timeout': '1h',\n",
      " 'workflowUri': 's3://workflow/74722d2d140643109bd05fc95c3fb68e/workflows.tar.gz'}\n"
     ]
    }
   ],
   "source": [
    "response_resnet50_train = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"init_model\",\n",
    "    entry_point_kwargs=\" \".join([\n",
    "        \"-P batch_size=20\",\n",
    "        \"-P model_architecture=resnet50\",\n",
    "        f\"-P data_dir={DATASET_DIR}/images/ILSVRC/Data/CLS-LOC/val-sorted-1000\",\n",
    "    ]),\n",
    "    queue=\"tensorflow_gpu\",\n",
    "    timeout=\"1h\",\n",
    ")\n",
    "\n",
    "print(\"Initialization job for ResNet50 neural network submitted\")\n",
    "print(\"\")\n",
    "pprint.pprint(response_resnet50_train)\n",
    "\n",
    "response_resnet50_train = get_run_id(response_resnet50_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploying and Testing Adversarial Patches\n",
    "\n",
    "Now we will apply the adversarial patches over our test set and evaluate the performance of the baseline model on the adversarial patches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patch attack (ResNet50 architecture) job submitted\n",
      "\n",
      "{'createdOn': '2021-02-14T21:13:18.482847',\n",
      " 'dependsOn': '5e30b0eb-de4c-4b5c-a949-1fe044466845',\n",
      " 'entryPoint': 'gen_patch',\n",
      " 'entryPointKwargs': '-P '\n",
      "                     'model=howard_imagenet_adversarial_patch_default_pretrained_resnet50/None '\n",
      "                     '-P '\n",
      "                     'data_dir=/nfs/data/ImageNet-Kaggle-2017/images/ILSVRC/Data/CLS-LOC/val-sorted-5000 '\n",
      "                     '-P num_patch_gen_samples=10 -P num_patch=1',\n",
      " 'experimentId': 20,\n",
      " 'jobId': 'c765c7ef-0f3a-4038-a673-974403cf81e4',\n",
      " 'lastModified': '2021-02-14T21:13:18.482847',\n",
      " 'mlflowRunId': None,\n",
      " 'queueId': 2,\n",
      " 'status': 'queued',\n",
      " 'timeout': '24h',\n",
      " 'workflowUri': 's3://workflow/db2a7028451843c8a149172808a89a47/workflows.tar.gz'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create Patches\n",
    "response_resnet50_patch = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"gen_patch\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P model={EXPERIMENT_NAME}_default_pretrained_resnet50/None\",\n",
    "            f\"-P data_dir={DATASET_DIR}/images/ILSVRC/Data/CLS-LOC/val-sorted-5000\",\n",
    "            \"-P num_patch_gen_samples=10\",\n",
    "            \"-P num_patch=1\",\n",
    "        ]\n",
    "    ),\n",
    "    queue=\"tensorflow_gpu\",\n",
    "    depends_on=response_resnet50_train[\"jobId\"],\n",
    ")\n",
    "\n",
    "print(\"Patch attack (ResNet50 architecture) job submitted\")\n",
    "print(\"\")\n",
    "pprint.pprint(response_resnet50_patch)\n",
    "print(\"\")\n",
    "\n",
    "response_resnet50_patch = get_run_id(response_resnet50_patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patch deployment (ResNet50 architecture) job submitted\n",
      "\n",
      "{'createdOn': '2021-02-14T21:14:01.171780',\n",
      " 'dependsOn': 'c765c7ef-0f3a-4038-a673-974403cf81e4',\n",
      " 'entryPoint': 'deploy_patch',\n",
      " 'entryPointKwargs': '-P run_id=db570666377141f2aa28f7ea49207e4a -P '\n",
      "                     'model=howard_imagenet_adversarial_patch_default_pretrained_resnet50/None '\n",
      "                     '-P '\n",
      "                     'data_dir=/nfs/data/ImageNet-Kaggle-2017/images/ILSVRC/Data/CLS-LOC/val-sorted-5000 '\n",
      "                     '-P batch_size=500',\n",
      " 'experimentId': 20,\n",
      " 'jobId': 'a26bd59f-dea5-4bb8-8f48-d2a3aabd066b',\n",
      " 'lastModified': '2021-02-14T21:14:01.171780',\n",
      " 'mlflowRunId': None,\n",
      " 'queueId': 2,\n",
      " 'status': 'queued',\n",
      " 'timeout': '24h',\n",
      " 'workflowUri': 's3://workflow/65c5c2c8758540c9a4d826289c306b55/workflows.tar.gz'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Deploy Patch attack on test set.\n",
    "response_deploy_resnet50_patch_testing = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"deploy_patch\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P run_id={response_resnet50_patch['mlflowRunId']}\",\n",
    "            f\"-P model={EXPERIMENT_NAME}_default_pretrained_resnet50/None\",\n",
    "            f\"-P data_dir={DATASET_DIR}/images/ILSVRC/Data/CLS-LOC/val-sorted-5000\",\n",
    "            \"-P batch_size=500\",\n",
    "        ]\n",
    "    ),\n",
    "    queue=\"tensorflow_gpu\",\n",
    "    depends_on=response_resnet50_patch[\"jobId\"],\n",
    ")\n",
    "\n",
    "print(\"Patch deployment (ResNet50 architecture) job submitted\")\n",
    "print(\"\")\n",
    "pprint.pprint(response_deploy_resnet50_patch_testing)\n",
    "print(\"\")\n",
    "\n",
    "response_deploy_resnet50_patch_testing = get_run_id(response_deploy_resnet50_patch_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patch evaluation (ResNet50 architecture) job submitted\n",
      "\n",
      "{'createdOn': '2021-02-14T21:21:28.909947',\n",
      " 'dependsOn': 'a26bd59f-dea5-4bb8-8f48-d2a3aabd066b',\n",
      " 'entryPoint': 'infer',\n",
      " 'entryPointKwargs': '-P run_id=24345f87b38c4278b6cb1c9a95be719f -P '\n",
      "                     'model=howard_imagenet_adversarial_patch_default_pretrained_resnet50/None '\n",
      "                     '-P model_architecture=resnet50 -P batch_size=100 -P '\n",
      "                     'dataset_tar_name=adversarial_patch_dataset.tar.gz -P '\n",
      "                     'dataset_name=adv_patch_dataset',\n",
      " 'experimentId': 20,\n",
      " 'jobId': '35fdd227-e6fe-4e13-b134-105c54c56056',\n",
      " 'lastModified': '2021-02-14T21:21:28.909947',\n",
      " 'mlflowRunId': None,\n",
      " 'queueId': 2,\n",
      " 'status': 'queued',\n",
      " 'timeout': '24h',\n",
      " 'workflowUri': 's3://workflow/f0aa7f99e40d41fda8f67461ff9fa30c/workflows.tar.gz'}\n",
      "\n",
      "{'accuracy': 0.5720999836921692,\n",
      " 'auc': 0.9339516162872314,\n",
      " 'fn': 5038.0,\n",
      " 'fp': 1809.0,\n",
      " 'loss': 1.9994313210344161,\n",
      " 'precision': 0.7328311800956726,\n",
      " 'recall': 0.49619999527931213,\n",
      " 'tn': 9988191.0,\n",
      " 'tp': 4962.0}\n"
     ]
    }
   ],
   "source": [
    "# Check patched dataset results   \n",
    "response_resnet50_infer_resnet50_patch = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"infer\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P run_id={response_deploy_resnet50_patch_testing['mlflowRunId']}\",\n",
    "            f\"-P model={EXPERIMENT_NAME}_default_pretrained_resnet50/None\",\n",
    "            \"-P model_architecture=resnet50\",\n",
    "            \"-P batch_size=100\",\n",
    "            \"-P dataset_tar_name=adversarial_patch_dataset.tar.gz\",\n",
    "            \"-P dataset_name=adv_patch_dataset\",\n",
    "            \n",
    "        ]\n",
    "    ),\n",
    "    queue=\"tensorflow_gpu\",\n",
    "    depends_on=response_deploy_resnet50_patch_testing[\"jobId\"],\n",
    ")\n",
    "\n",
    "print(\"Patch evaluation (ResNet50 architecture) job submitted\")\n",
    "print(\"\")\n",
    "pprint.pprint(response_resnet50_infer_resnet50_patch)\n",
    "print(\"\")\n",
    "\n",
    "response_resnet50_infer_resnet50_patch = get_run_id(response_resnet50_infer_resnet50_patch)\n",
    "print_mlflow_results(response_resnet50_infer_resnet50_patch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying the MLFlow Tracking Service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently the lab API can only be used to register experiments and start jobs, so if users wish to extract their results programmatically, they can use the `MlflowClient()` class from the `mlflow` Python package to connect and query their results.\n",
    "Since we captured the run ids generated by MLFlow, we can easily retrieve the data logged about one of our jobs and inspect the results.\n",
    "To start the client, we simply need to run,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_client = MlflowClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The client uses the environment variable `MLFLOW_TRACKING_URI` to figure out how to connect to the MLFlow Tracking Service, which we configured near the top of this notebook.\n",
    "To query the results of one of our runs, we just need to pass the run id to the client's `get_run()` method.\n",
    "As an example, let's query the run results for the patch attack applied to the ResNet50 architecture,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_resnet50 = mlflow_client.get_run(response_resnet50_infer_resnet50_patch[\"mlflowRunId\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the request completed successfully, we should now be able to query data collected during the run.\n",
    "For example, to review the collected metrics, we just use,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.5720999836921692,\n",
      " 'auc': 0.9339516162872314,\n",
      " 'fn': 5038.0,\n",
      " 'fp': 1809.0,\n",
      " 'loss': 1.9994313210344161,\n",
      " 'precision': 0.7328311800956726,\n",
      " 'recall': 0.49619999527931213,\n",
      " 'tn': 9988191.0,\n",
      " 'tp': 4962.0}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(run_resnet50.data.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To review the run's parameters, we use,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': '100',\n",
      " 'dataset_name': 'adv_patch_dataset',\n",
      " 'dataset_tar_name': 'adversarial_patch_dataset.tar.gz',\n",
      " 'model': 'howard_imagenet_adversarial_patch_default_pretrained_resnet50/None',\n",
      " 'model_architecture': 'resnet50',\n",
      " 'run_id': '24345f87b38c4278b6cb1c9a95be719f',\n",
      " 'seed': '-1'}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(run_resnet50.data.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To review the run's tags, we use,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mlflow.project.backend': 'securingai',\n",
      " 'mlflow.project.entryPoint': 'infer',\n",
      " 'mlflow.source.name': '/work/tmps38n_pty',\n",
      " 'mlflow.source.type': 'PROJECT',\n",
      " 'mlflow.user': 'securingai',\n",
      " 'securingai.dependsOn': 'a26bd59f-dea5-4bb8-8f48-d2a3aabd066b',\n",
      " 'securingai.jobId': '35fdd227-e6fe-4e13-b134-105c54c56056',\n",
      " 'securingai.queue': 'tensorflow_gpu'}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(run_resnet50.data.tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many things you can query using the MLFlow client.\n",
    "[The MLFlow documentation gives a full overview of the methods that are available](https://www.mlflow.org/docs/latest/python_api/mlflow.tracking.html#mlflow.tracking.MlflowClient)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
