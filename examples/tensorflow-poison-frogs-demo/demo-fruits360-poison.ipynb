{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Poison Frogs Fruits360 demo for Securing AI Lab deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** This demo is specifically for the NCCoE DGX Workstation with hostname `dgx-station-2`.\n",
    "\n",
    "Port forwarding is required in order to run this demo.\n",
    "The recommended port mapping is as follows:\n",
    "\n",
    "- Map `localhost:30080` on laptop to `localhost:30080` on `dgx-station-2`\n",
    "- Map `localhost:35000` on laptop to `localhost:35000` on `dgx-station-2`\n",
    "\n",
    "A sample SSH config file that enables the above port forwarding is provided below,\n",
    "\n",
    "> ⚠️ **Edits required**: replace `username` with your assigned username _on the NCCoE virtual machines_!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```conf\n",
    "# vm hostname: jumphost001\n",
    "Host nccoe-jumphost001\n",
    "    Hostname 10.33.53.98\n",
    "    User username\n",
    "    Port 54131\n",
    "    IdentityFile %d/.ssh/nccoe-vm\n",
    "\n",
    "# vm hostname: dgx-station-2\n",
    "Host nccoe-k8s-gpu002\n",
    "    Hostname 192.168.1.28\n",
    "    User username\n",
    "    Port 22\n",
    "    IdentityFile %d/.ssh/nccoe-vm\n",
    "    ProxyJump nccoe-jumphost001\n",
    "    LocalForward 30080 localhost:30080\n",
    "    LocalForward 35000 localhost:35000\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, connect to the NCCoE VPN and SSH into the DGX Workstation,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "ssh nccoe-k8s-gpu002\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we import the necessary Python modules and ensure the proper environment variables are set so that all the code blocks will work as expected,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages from the Python standard library\n",
    "import os\n",
    "import pprint\n",
    "import time\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "import tarfile\n",
    "# Please enter custom username here.\n",
    "USERNAME = \"howard\"\n",
    "\n",
    "# Filter out warning messages\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Default address for accessing the RESTful API service\n",
    "RESTAPI_ADDRESS = \"http://localhost:30080\"\n",
    "\n",
    "# Base API address\n",
    "RESTAPI_API_BASE = f\"{RESTAPI_ADDRESS}/api\"\n",
    "\n",
    "# Default address for accessing the MLFlow Tracking server\n",
    "MLFLOW_TRACKING_URI = \"http://localhost:35000\"\n",
    "\n",
    "# Path to workflows archive\n",
    "WORKFLOWS_TAR_GZ = Path(\"workflows.tar.gz\")\n",
    "\n",
    "# Experiment name (note the username_ prefix convention)\n",
    "EXPERIMENT_NAME = f\"{USERNAME}_fruits360_poison_frogs\"\n",
    "\n",
    "# Set MLFLOW_TRACKING_URI variable, used to connect to MLFlow Tracking service\n",
    "if os.getenv(\"MLFLOW_TRACKING_URI\") is None:\n",
    "    os.environ[\"MLFLOW_TRACKING_URI\"] = MLFLOW_TRACKING_URI\n",
    "\n",
    "# Import third-party Python packages\n",
    "import numpy as np\n",
    "import requests\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# Import utils.py file\n",
    "import utils\n",
    "\n",
    "# Create random number generator\n",
    "rng = np.random.default_rng(54399264723942495723666216079516778448)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the Makefile works in your environment by executing the `bash` code block below,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getenv(\"AWS_ACCESS_KEY_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Running this will just list the available rules defined in the demo's Makefile.\n",
    "make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit and run jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The jobs that we will be running are implemented in the Python source files under `src/`, which will be executed using the entrypoints defined in the `MLproject` file.\n",
    "To get this information into the architecture, we need to package those files up into an archive and upload it to the lab API.\n",
    "For convenience, the `Makefile` provides a rule for creating the archive file, just run `make workflows`,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Create the workflows.tar.gz file\n",
    "make workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To connect with the endpoint, we will use a client class defined in the `utils.py` file that is able to connect with the lab's RESTful API using the HTTP protocol.\n",
    "We connect using the client below,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restapi_client = utils.SecuringAIClient(address=RESTAPI_API_BASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to register an experiment under which to collect our job runs.\n",
    "The code below checks if the relevant experiment named `\"jglasbrenner_mnist\"` exists.\n",
    "If it does, then it just returns info about the experiment, if it doesn't, it then registers the new experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_experiment = restapi_client.get_experiment_by_name(name=EXPERIMENT_NAME)\n",
    "\n",
    "if response_experiment is None or \"Not Found\" in response_experiment.get(\"message\", []):\n",
    "    response_experiment = restapi_client.register_experiment(name=EXPERIMENT_NAME)\n",
    "\n",
    "response_experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to train our model.\n",
    "We will be using the V100 GPUs that are available on the DGX Workstation, which we can use by submitting our job to the `\"tensorflow_gpu\"` queue.\n",
    "We will train three models, a shallow network model, a LeNet-5 model, and an AlexNet model,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlflow_run_id_is_not_known(response_fgm):\n",
    "    return response_fgm[\"mlflowRunId\"] is None and response_fgm[\"status\"] not in [\n",
    "        \"failed\",\n",
    "        \"finished\",\n",
    "    ]\n",
    "\n",
    "response_vgg16_train = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"train\",\n",
    "    entry_point_kwargs=\" \".join([\n",
    "        \"-P batch_size=20\",\n",
    "        \"-P register_model=True\",\n",
    "        \"-P model_architecture=vgg16\",\n",
    "        \"-P epochs=30\",\n",
    "        \"-P data_dir_train=/nfs/data/Fruits360-Kaggle-2019/fruits-360/Training\",\n",
    "        \"-P data_dir_test=/nfs/data/Fruits360-Kaggle-2019/fruits-360/Test\",\n",
    "    ]),\n",
    "    queue=\"tensorflow_gpu\",\n",
    "    timeout=\"1h\",\n",
    ")\n",
    "\n",
    "print(\"Training job for VGG16 neural network submitted\")\n",
    "print(\"\")\n",
    "pprint.pprint(response_vgg16_train)\n",
    "\n",
    "while mlflow_run_id_is_not_known(response_vgg16_train):\n",
    "    time.sleep(1)\n",
    "    response_vgg16_train = restapi_client.get_job_by_id(\n",
    "        response_vgg16_train[\"jobId\"]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poison Frogs: Image Selection\n",
    "### Now we will examine the test set and select a particular image we'd like to corrupt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model download:\n",
    "import requests\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "def load_model_from_job_run(run_id, model_dir):\n",
    "    params = {\"path\":\"model/data/model.h5\", \"run_uuid\": run_id}\n",
    "    r = requests.get('http://localhost:35000/get-artifact', params=params)\n",
    "    print(\"Accessing MLflow Client Server. Downloading model files.\")\n",
    "    print(r.headers)\n",
    "    model_path = os.path.join(model_dir, 'model.h5')\n",
    "    \n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "        \n",
    "    with open(model_path, \"wb+\") as f:\n",
    "        f.write(r.content)\n",
    "    \n",
    "    return tf.keras.models.load_model(model_path)\n",
    "\n",
    "def load_images_from_job_run(run_id, image_dir):\n",
    "    params = {\"path\":\"adversarial_poison.tar.gz\", \"run_uuid\": run_id}\n",
    "    r = requests.get('http://localhost:35000/get-artifact', params=params)\n",
    "    print(\"Accessing MLflow Client Server. Downloading image files.\")\n",
    "    print(r.headers)\n",
    "    zip_path = os.path.join(image_dir, 'adversarial_poison.tar.gz')\n",
    "    \n",
    "    if not os.path.exists(image_dir):\n",
    "        os.makedirs(image_dir)\n",
    "        \n",
    "    with open(zip_path, \"wb+\") as f:\n",
    "        f.write(r.content)\n",
    "    \n",
    "    with tarfile.open(zip_path, \"r:gz\") as f:\n",
    "        f.extractall(path=image_dir)\n",
    "    \n",
    "# Wait for model to become available.\n",
    "while response_vgg16_train['status'] != \"finished\":\n",
    "    time.sleep(1)\n",
    "    response_vgg16_train = restapi_client.get_job_by_id(\n",
    "        response_vgg16_train[\"jobId\"]\n",
    "    )  \n",
    "    \n",
    "original_model = load_model_from_job_run(response_vgg16_train['mlflowRunId'], './original_model')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import random\n",
    "\n",
    "\n",
    "def create_class_list(imagedir):\n",
    "    class_names = []\n",
    "    for item in os.listdir(imagedir):\n",
    "        if os.path.isdir(imagedir+\"/\"+item):\n",
    "            class_names.append(item)\n",
    "    return sorted(class_names)\n",
    "\n",
    "class_names = create_class_list(\"/nfs/1/datasets/Fruits360-Kaggle-2019/fruits-360/Test\")\n",
    "\n",
    "image_list = []\n",
    "for path, subdirs, files in os.walk(\"/nfs/1/datasets/Fruits360-Kaggle-2019/fruits-360/Test\"):\n",
    "    for name in files:\n",
    "        image_list.append(os.path.join(path, name))\n",
    "        \n",
    "class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we'll randomly parse through images of interest. \n",
    "\n",
    "The code below will pull an image from the MNIST test set, and run it through the trained mode.\n",
    "\n",
    "For this demo, we'd like to start with an image that the model predicts correctly.\n",
    "\n",
    "Rerun the the cell below until an image of interest is selected. Then proceed to the rest of the demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_file = np.random.choice(image_list)\n",
    "(label,filename) = random_file.split('/')[-2:]\n",
    "\n",
    "# load and show an image with Pillow\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Open the image form working directory\n",
    "image = Image.open(random_file)\n",
    "image = image.resize((224, 224))\n",
    "\n",
    "# Summarize some details about the image\n",
    "print(\"Image label: \" + str(label) )\n",
    "predicted_label = class_names[np.argmax(original_model.predict(np.reshape(image, (1,224,224,3))), axis=1)[0]]\n",
    "print(\"Predicted label: \" + predicted_label)\n",
    "print(\"Filename: \" + filename)\n",
    "\n",
    "# Show the image\n",
    "image = np.asarray(image)\n",
    "fig = plt.figure\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image label: Redcurrant\n",
    "#Predicted label: Redcurrant\n",
    "#Filename: r_248_100.jpg\n",
    "\n",
    "# Set target image to propogate into clean label images from another class\n",
    "target_file = filename #\"r_5_100.jpg\"\n",
    "original_label = label #\"Passion Fruit\"\n",
    "\n",
    "# Set target label here, this will be the new label that the target image will be reclassified as.\n",
    "target_label = class_names[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating and Deploying Poisoned Images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will create our set of poisoned images and examine them visually.\n",
    "\n",
    "Start by submitting the poison generation job below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create poisoned images.\n",
    "fixed_original_label = original_label.replace(\" \", \"\\\\ \")\n",
    "response_gen_poison_vgg16 = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"gen_poison\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P model={EXPERIMENT_NAME}_vgg16/1\",\n",
    "            \"-P model_architecture=vgg16\",\n",
    "            \"-P data_dir=/nfs/data/Fruits360-Kaggle-2019/fruits-360/Training\",\n",
    "            f\"-P target_image_path=/nfs/data/Fruits360-Kaggle-2019/fruits-360/Test/{fixed_original_label}/{target_file}\",\n",
    "            f\"-P target_class={class_names.index(target_label)}\",\n",
    "            \"-P feature_layer_index=-2\",\n",
    "            \"-P max_iter=100\",\n",
    "            \"-P similarity_coeff=512\",\n",
    "            \"-P watermark=.3\",\n",
    "            \"-P batch_size=100\",\n",
    "            \"-P num_poisoned_batches=1\"\n",
    "            \n",
    "        ]\n",
    "    ),\n",
    "    queue=\"tensorflow_cpu\",\n",
    "    depends_on=response_vgg16_train[\"jobId\"],\n",
    ")\n",
    "\n",
    "print(\"Poison frogs attack (VGG16 architecture) job submitted\")\n",
    "print(\"\")\n",
    "pprint.pprint(response_gen_poison_vgg16)\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "while mlflow_run_id_is_not_known(response_gen_poison_vgg16):\n",
    "    time.sleep(1)\n",
    "    response_gen_poison_vgg16 = restapi_client.get_job_by_id(response_gen_poison_vgg16[\"jobId\"])\n",
    "    \n",
    "# Wait for attack to finish.\n",
    "while response_gen_poison_vgg16['status'] != \"finished\":\n",
    "    time.sleep(1)\n",
    "    response_gen_poison_vgg16 = restapi_client.get_job_by_id(\n",
    "        response_gen_poison_vgg16[\"jobId\"]\n",
    "    )  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will create a set of poisoned images that we can insert into the MNIST training set.\n",
    "\n",
    "To see if the images can past inspection, we will now examine the image similarity metrics generated from our job and some sample images from the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_client = MlflowClient()\n",
    "run_id = response_gen_poison_vgg16[\"mlflowRunId\"]\n",
    "view_run_vgg16 = mlflow_client.get_run(run_id)\n",
    "pprint.pprint(view_run_vgg16.data.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will also visually inspect the changes made to each poisoned image from its original counterpart:\n",
    "load_images_from_job_run(run_id, \"./poisoned_images_fruits\")\n",
    "\n",
    "def get_target_class_name(poison_dir):\n",
    "    for item in os.listdir(poison_dir):\n",
    "        if os.path.isdir(poison_dir +\"/\"+ item):\n",
    "            return item\n",
    "    return \"None\"\n",
    "\n",
    "print(get_target_class_name(\"./poisoned_images_fruits/adv_poison_data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def check_image(image_path, descriptor):\n",
    "    image = Image.open(image_path).resize((224,224))\n",
    "    image = np.asarray(image)\n",
    "        # plot the sample\n",
    "    fig = plt.figure\n",
    "    plt.title(descriptor)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.show()\n",
    "    return image\n",
    "\n",
    "\n",
    "def compare_image_sets(original_model, src_image_dir, corrupt_image_dir):\n",
    "    corrupt_image_list = [os.path.join(corrupt_image_dir, f) for f in os.listdir(corrupt_image_dir) if os.path.isfile(os.path.join(corrupt_image_dir, f))]\n",
    "    \n",
    "    corrupt_image = np.random.choice(corrupt_image_list,1)[0]\n",
    "    \n",
    "    original_image = os.path.join(src_image_dir, corrupt_image.split(\"poisoned_\")[-1])\n",
    "    \n",
    "    target_image =  f\"/nfs/1/datasets/Fruits360-Kaggle-2019/fruits-360/Test/{original_label}/{target_file}\"\n",
    "    \n",
    "    image = check_image(target_image, \"Target Test Image\")\n",
    "    print(\"Model prediction: \" + str(np.argmax(original_model.predict(np.reshape(image, (1,224,224,3))), axis=1)[0]))\n",
    "\n",
    "    print(\"Image: \" + original_image)\n",
    "    image = check_image(original_image, \"Original Training Image\")\n",
    "    print(\"Model prediction: \" + str(np.argmax(original_model.predict(np.reshape(image, (1,224,224,3))), axis=1)[0]))\n",
    "    image = check_image(corrupt_image, \"Corrupted Training Image\")\n",
    "    print(\"Model prediction: \" + str(np.argmax(original_model.predict(np.reshape(image, (1,224,224,3))), axis=1)[0]))\n",
    "\n",
    "fixed_target_label = target_label#.replace(\" \", \"\\\\ \")\n",
    "src  = Path(f\"/nfs/1/datasets/Fruits360-Kaggle-2019/fruits-360/Training/{fixed_target_label}\")\n",
    "corr_src = Path(f\"./poisoned_images_fruits/adv_poison_data/{fixed_target_label}\")\n",
    "\n",
    "compare_image_sets(original_model,src, corr_src)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy Poison to Dataset\n",
    "response_deploy_poison_vgg16 = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"deploy_poison\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P run_id={response_gen_poison_vgg16['mlflowRunId']}\",\n",
    "            \"-P data_dir=/nfs/data/Fruits360-Kaggle-2019/fruits-360/Training\",\n",
    "            \"-P poison_deployment_method=replace\",\n",
    "            #\"-P num_poisoned_images=100\",\n",
    "        ]\n",
    "    ),\n",
    "    queue=\"tensorflow_cpu\",\n",
    "    depends_on=response_gen_poison_vgg16[\"jobId\"],\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Poison deployment (LeNet-5 architecture) job submitted\")\n",
    "print(\"\")\n",
    "pprint.pprint(response_deploy_poison_vgg16)\n",
    "print(\"\")\n",
    "\n",
    "# Wait for Poison deployment to finish.\n",
    "while mlflow_run_id_is_not_known(response_deploy_poison_vgg16):\n",
    "    time.sleep(1)\n",
    "    response_deploy_poison_vgg16 = restapi_client.get_job_by_id(response_deploy_poison_vgg16[\"jobId\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, train and retest poisoned dataset.\n",
    "\n",
    "response_deploy_vgg16_poison_frogs_mnist_adv_training = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"train\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P testing_dataset_run_id=None\",\n",
    "            f\"-P training_dataset_run_id={response_deploy_poison_vgg16['mlflowRunId']}\",\n",
    "            \"-P batch_size=256\",\n",
    "            \"-P register_model=True\",\n",
    "            \"-P model_architecture=vgg16\",\n",
    "            f\"-P model_tag=poisoned_runID_{response_deploy_poison_vgg16['mlflowRunId']}\",\n",
    "            \"-P epochs=30\",\n",
    "            \"-P data_dir_train=/nfs/data/\",\n",
    "            \"-P data_dir_test=/nfs/data/Fruits360-Kaggle-2019/fruits-360/Test\",\n",
    "            \"-P load_dataset_from_mlruns=True\",\n",
    "\n",
    "        ]\n",
    "    ),\n",
    "    \n",
    "    queue=\"tensorflow_gpu\",\n",
    "    depends_on=response_deploy_poison_vgg16[\"jobId\"],\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Poison frogs adversarial training (LeNet-5 architecture) job submitted\")\n",
    "print(\"\")\n",
    "pprint.pprint(response_deploy_vgg16_poison_frogs_mnist_adv_training)\n",
    "print(\"\")\n",
    "\n",
    "# Wait for training to finish.\n",
    "while mlflow_run_id_is_not_known(response_deploy_vgg16_poison_frogs_mnist_adv_training):\n",
    "    time.sleep(1)\n",
    "    response_deploy_vgg16_poison_frogs_mnist_adv_training = restapi_client.get_job_by_id(response_deploy_vgg16_poison_frogs_mnist_adv_training[\"jobId\"])\n",
    "    \n",
    "while response_deploy_vgg16_poison_frogs_mnist_adv_training['status'] != \"finished\":\n",
    "    time.sleep(1)\n",
    "    response_deploy_vgg16_poison_frogs_mnist_adv_training = restapi_client.get_job_by_id(\n",
    "        response_deploy_vgg16_poison_frogs_mnist_adv_training[\"jobId\"]\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, let's check if the attack worked, the target image should be reclassified as beloning to the new target class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupt_model = load_model_from_job_run(response_deploy_vgg16_poison_frogs_mnist_adv_training['mlflowRunId'], './test_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_image = f\"/nfs/1/datasets/Fruits360-Kaggle-2019/fruits-360/Test/{original_label}/{target_file}\"\n",
    "\n",
    "# load and show an image with Pillow\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "# Open the image form working directory\n",
    "image = Image.open(target_image).resize((224,224))\n",
    "\n",
    "# summarize some details about the image\n",
    "print(\"Original Image label: \" + str(original_label) )\n",
    "#print(\"Predicted label (original model): \" + str(np.argmax(original_model.predict(np.reshape(image, (1,224,224,3))), axis=1)[0]))\n",
    "print(\"Predicted label (corrupted model): \" + class_names[np.argmax(corrupt_model.predict(np.reshape(image, (1,224,224,3))), axis=1)[0]])\n",
    "image = np.asarray(image)\n",
    "\n",
    "# display the array of pixels as an image\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
