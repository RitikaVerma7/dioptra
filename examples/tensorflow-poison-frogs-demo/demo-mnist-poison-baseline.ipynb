{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Poison Frogs MNIST demo for Securing AI Lab deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** This demo is specifically for the NCCoE DGX Workstation with hostname `dgx-station-2`.\n",
    "\n",
    "Port forwarding is required in order to run this demo.\n",
    "The recommended port mapping is as follows:\n",
    "\n",
    "- Map `localhost:30080` on laptop to `localhost:30080` on `dgx-station-2`\n",
    "- Map `localhost:35000` on laptop to `localhost:35000` on `dgx-station-2`\n",
    "\n",
    "A sample SSH config file that enables the above port forwarding is provided below,\n",
    "\n",
    "> ⚠️ **Edits required**: replace `username` with your assigned username _on the NCCoE virtual machines_!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```conf\n",
    "# vm hostname: jumphost001\n",
    "Host nccoe-jumphost001\n",
    "    Hostname 10.33.53.98\n",
    "    User username\n",
    "    Port 54131\n",
    "    IdentityFile %d/.ssh/nccoe-vm\n",
    "\n",
    "# vm hostname: dgx-station-2\n",
    "Host nccoe-k8s-gpu002\n",
    "    Hostname 192.168.1.28\n",
    "    User username\n",
    "    Port 22\n",
    "    IdentityFile %d/.ssh/nccoe-vm\n",
    "    ProxyJump nccoe-jumphost001\n",
    "    LocalForward 30080 localhost:30080\n",
    "    LocalForward 35000 localhost:35000\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, connect to the NCCoE VPN and SSH into the DGX Workstation,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "ssh nccoe-k8s-gpu002\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we import the necessary Python modules and ensure the proper environment variables are set so that all the code blocks will work as expected,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages from the Python standard library\n",
    "import os\n",
    "import pprint\n",
    "import time\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "import tarfile\n",
    "\n",
    "# Please enter your username here.\n",
    "USERNAME = \"howard\"\n",
    "\n",
    "# Filter out warning messages\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Default address for accessing the RESTful API service\n",
    "RESTAPI_ADDRESS = \"http://localhost:30080\"\n",
    "\n",
    "# Base API address\n",
    "RESTAPI_API_BASE = f\"{RESTAPI_ADDRESS}/api\"\n",
    "\n",
    "# Default address for accessing the MLFlow Tracking server\n",
    "MLFLOW_TRACKING_URI = \"http://localhost:35000\"\n",
    "\n",
    "# Path to workflows archive\n",
    "WORKFLOWS_TAR_GZ = Path(\"workflows.tar.gz\")\n",
    "\n",
    "# Experiment name (note the username_ prefix convention)\n",
    "EXPERIMENT_NAME = f\"{USERNAME}_mnist_poison_frogs\"\n",
    "\n",
    "# Set MLFLOW_TRACKING_URI variable, used to connect to MLFlow Tracking service\n",
    "if os.getenv(\"MLFLOW_TRACKING_URI\") is None:\n",
    "    os.environ[\"MLFLOW_TRACKING_URI\"] = MLFLOW_TRACKING_URI\n",
    "\n",
    "# Import third-party Python packages\n",
    "import numpy as np\n",
    "import requests\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# Import utils.py file\n",
    "import utils\n",
    "\n",
    "# Create random number generator\n",
    "rng = np.random.default_rng(54399264723942495723666216079516778448)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the Makefile works in your environment by executing the `bash` code block below,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mAvailable rules:\u001b[m\n",
      "\n",
      "\u001b[36mclean              \u001b[m Remove temporary files \n",
      "\u001b[36mdata               \u001b[m Download and prepare MNIST dataset \n",
      "\u001b[36minitdb             \u001b[m Initialize the RESTful API database \n",
      "\u001b[36mservices           \u001b[m Launch the Minio S3 and MLFlow Tracking services \n",
      "\u001b[36mteardown           \u001b[m Destroy service containers \n",
      "\u001b[36mworkflows          \u001b[m Create workflows tarball \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hhuang/.conda/envs/tensorflow-mnist-classifier/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Running this will just list the available rules defined in the demo's Makefile.\n",
    "make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit and run jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The jobs that we will be running are implemented in the Python source files under `src/`, which will be executed using the entrypoints defined in the `MLproject` file.\n",
    "To get this information into the architecture, we need to package those files up into an archive and upload it to the lab API.\n",
    "For convenience, the `Makefile` provides a rule for creating the archive file, just run `make workflows`,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make: Nothing to be done for 'workflows'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hhuang/.conda/envs/tensorflow-mnist-classifier/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Create the workflows.tar.gz file\n",
    "make workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To connect with the endpoint, we will use a client class defined in the `utils.py` file that is able to connect with the lab's RESTful API using the HTTP protocol.\n",
    "We connect using the client below,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hhuang/.conda/envs/tensorflow-mnist-classifier/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "restapi_client = utils.SecuringAIClient(address=RESTAPI_API_BASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to register an experiment under which to collect our job runs.\n",
    "The code below checks if the relevant experiment named `howard_mnist_poison_frogs` exists.\n",
    "If it does, then it just returns info about the experiment, if it doesn't, it then registers the new experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'experimentId': 9,\n",
       " 'lastModified': '2020-11-05T07:06:19.144936',\n",
       " 'createdOn': '2020-11-05T07:06:19.144936',\n",
       " 'name': 'howard_mnist_poison_frogs'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_experiment = restapi_client.get_experiment_by_name(name=EXPERIMENT_NAME)\n",
    "\n",
    "if response_experiment is None or \"Not Found\" in response_experiment.get(\"message\", []):\n",
    "    response_experiment = restapi_client.register_experiment(name=EXPERIMENT_NAME)\n",
    "\n",
    "response_experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to train our model.\n",
    "We will be using the V100 GPUs that are available on the DGX Workstation, which we can use by submitting our job to the `\"tensorflow_gpu\"` queue.\n",
    "We will train three models, a shallow network model, a LeNet-5 model, and an AlexNet model,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training job for LeNet-5 neural network submitted\n",
      "\n",
      "{'createdOn': '2020-12-10T08:18:41.901417',\n",
      " 'dependsOn': None,\n",
      " 'entryPoint': 'train',\n",
      " 'entryPointKwargs': '-P batch_size=256 -P register_model=True -P '\n",
      "                     'model_architecture=le_net -P epochs=30 -P '\n",
      "                     'data_dir_train=/nfs/data/Mnist/training -P '\n",
      "                     'data_dir_test=/nfs/data/Mnist/testing',\n",
      " 'experimentId': 9,\n",
      " 'jobId': 'bb473293-6d09-41b1-b4f5-2da28715c134',\n",
      " 'lastModified': '2020-12-10T08:18:41.901417',\n",
      " 'mlflowRunId': None,\n",
      " 'queueId': 2,\n",
      " 'status': 'queued',\n",
      " 'timeout': '1h',\n",
      " 'workflowUri': 's3://workflow/f5a13c2f02734485a520074f0d86b2d2/workflows.tar.gz'}\n"
     ]
    }
   ],
   "source": [
    "def mlflow_run_id_is_not_known(response_fgm):\n",
    "    return response_fgm[\"mlflowRunId\"] is None and response_fgm[\"status\"] not in [\n",
    "        \"failed\",\n",
    "        \"finished\",\n",
    "    ]\n",
    "\n",
    "response_le_net_train = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"train\",\n",
    "    entry_point_kwargs=\" \".join([\n",
    "        \"-P batch_size=256\",\n",
    "        \"-P register_model=True\",\n",
    "        \"-P model_architecture=le_net\",\n",
    "        \"-P epochs=30\",\n",
    "        \"-P data_dir_train=/nfs/data/Mnist/training\",\n",
    "        \"-P data_dir_test=/nfs/data/Mnist/testing\",\n",
    "    ]),\n",
    "    queue=\"tensorflow_gpu\",\n",
    "    timeout=\"1h\",\n",
    "    \n",
    ")\n",
    "\n",
    "print(\"Training job for LeNet-5 neural network submitted\")\n",
    "print(\"\")\n",
    "pprint.pprint(response_le_net_train)\n",
    "\n",
    "while mlflow_run_id_is_not_known(response_le_net_train):\n",
    "    time.sleep(1)\n",
    "    response_le_net_train = restapi_client.get_job_by_id(\n",
    "        response_le_net_train[\"jobId\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poison Frogs: Image Selection\n",
    "\n",
    "Here we will set the target image and base class label to generate new poisoned images.\n",
    "\n",
    "The advanced demo covers additional steps to help users select their own target images for attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set target image to propogate into clean label images from another class\n",
    "target_file = \"01045.png\" \n",
    "original_label = 9\n",
    "\n",
    "# Set target label here, this will be the new label that the target image will be reclassified as.\n",
    "target_label = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating and Deploying Poisoned Images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will create our set of poisoned images.\n",
    "\n",
    "Start by submitting the poison generation job below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poison attack (LeNet-5 architecture) job submitted\n",
      "\n",
      "{'createdOn': '2020-12-10T08:18:55.870451',\n",
      " 'dependsOn': 'bb473293-6d09-41b1-b4f5-2da28715c134',\n",
      " 'entryPoint': 'gen_poison',\n",
      " 'entryPointKwargs': '-P model=howard_mnist_poison_frogs_le_net/1 -P '\n",
      "                     'model_architecture=le_net -P '\n",
      "                     'data_dir=/nfs/data/Mnist/training -P '\n",
      "                     'target_image_path=/nfs/data/Mnist/testing/9/01045.png -P '\n",
      "                     'target_class=6 -P feature_layer_index=-1 -P max_iter=100 '\n",
      "                     '-P similarity_coeff=512 -P watermark=0.30 -P '\n",
      "                     'batch_size=100 -P num_poisoned_batches=5',\n",
      " 'experimentId': 9,\n",
      " 'jobId': '61d2ebd1-baa9-4ee9-90df-b912f0d221f6',\n",
      " 'lastModified': '2020-12-10T08:18:55.870451',\n",
      " 'mlflowRunId': None,\n",
      " 'queueId': 2,\n",
      " 'status': 'queued',\n",
      " 'timeout': '24h',\n",
      " 'workflowUri': 's3://workflow/c2542da2451c423d90fe8b59f526aa07/workflows.tar.gz'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Create poisoned images.\n",
    "response_gen_poison_le_net = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"gen_poison\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P model={EXPERIMENT_NAME}_le_net/1\",\n",
    "            \"-P model_architecture=le_net\",\n",
    "            \"-P data_dir=/nfs/data/Mnist/training\",\n",
    "            f\"-P target_image_path=/nfs/data/Mnist/testing/{original_label}/{target_file}\",\n",
    "            f\"-P target_class={target_label}\",\n",
    "            \"-P feature_layer_index=-1\",\n",
    "            \"-P max_iter=100\",\n",
    "            \"-P similarity_coeff=512\",\n",
    "            \"-P watermark=0.30\", #.30\",\n",
    "            \"-P batch_size=100\",\n",
    "            \"-P num_poisoned_batches=5\"\n",
    "            \n",
    "        ]\n",
    "    ),\n",
    "    queue=\"tensorflow_gpu\",\n",
    "    depends_on=response_le_net_train[\"jobId\"],\n",
    ")\n",
    "\n",
    "print(\"Poison attack (LeNet-5 architecture) job submitted\")\n",
    "print(\"\")\n",
    "pprint.pprint(response_gen_poison_le_net)\n",
    "print(\"\")\n",
    "\n",
    "while mlflow_run_id_is_not_known(response_gen_poison_le_net):\n",
    "    time.sleep(1)\n",
    "    response_gen_poison_le_net = restapi_client.get_job_by_id(response_gen_poison_le_net[\"jobId\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will create a set of poisoned images that we can insert into the MNIST training set.\n",
    "\n",
    "To see if the images can past inspection, we will now examine the image similarity metrics generated from our job and some sample images from the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cosine_similarity_iqr': 0.08562535047531128,\n",
      " 'cosine_similarity_max': 0.9592462778091431,\n",
      " 'cosine_similarity_mean': 0.7673174142837524,\n",
      " 'cosine_similarity_median': 0.7654372453689575,\n",
      " 'cosine_similarity_min': 0.5430136919021606,\n",
      " 'cosine_similarity_stdev': 0.06320770829916,\n",
      " 'euclidean_distance_iqr': 0.9511409997940063,\n",
      " 'euclidean_distance_max': 10.493609428405762,\n",
      " 'euclidean_distance_mean': 8.393716812133789,\n",
      " 'euclidean_distance_median': 8.466426849365234,\n",
      " 'euclidean_distance_min': 4.388647079467773,\n",
      " 'euclidean_distance_stdev': 0.7700011730194092,\n",
      " 'l_infinity_norm_iqr': 0.0,\n",
      " 'l_infinity_norm_max': 1.0,\n",
      " 'l_infinity_norm_mean': 1.0,\n",
      " 'l_infinity_norm_median': 1.0,\n",
      " 'l_infinity_norm_min': 1.0,\n",
      " 'l_infinity_norm_stdev': 0.0,\n",
      " 'manhattan_distance_iqr': 16.112743377685547,\n",
      " 'manhattan_distance_max': 113.4078369140625,\n",
      " 'manhattan_distance_mean': 77.59153747558594,\n",
      " 'manhattan_distance_median': 78.39019775390625,\n",
      " 'manhattan_distance_min': 22.964698791503906,\n",
      " 'manhattan_distance_stdev': 12.528264999389648,\n",
      " 'wasserstein_distance_iqr': 0.020551971249562706,\n",
      " 'wasserstein_distance_max': 0.14465286038169753,\n",
      " 'wasserstein_distance_mean': 0.09896872480536396,\n",
      " 'wasserstein_distance_median': 0.09998749138796893,\n",
      " 'wasserstein_distance_min': 0.029291709143744453,\n",
      " 'wasserstein_distance_stdev': 0.015979966331303788}\n"
     ]
    }
   ],
   "source": [
    "# Wait for Poison attack to finish.\n",
    "while response_gen_poison_le_net['status'] != \"finished\":\n",
    "    time.sleep(1)\n",
    "    response_gen_poison_le_net = restapi_client.get_job_by_id(\n",
    "        response_gen_poison_le_net[\"jobId\"]\n",
    "    )   \n",
    "\n",
    "mlflow_client = MlflowClient()\n",
    "run_id = response_gen_poison_le_net[\"mlflowRunId\"]\n",
    "view_run_le_net = mlflow_client.get_run(run_id)\n",
    "pprint.pprint(view_run_le_net.data.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will deploy the poisoned images into the original target dataset for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poison deployment (LeNet-5 architecture) job submitted\n",
      "\n",
      "{'createdOn': '2020-12-10T08:25:14.127458',\n",
      " 'dependsOn': '61d2ebd1-baa9-4ee9-90df-b912f0d221f6',\n",
      " 'entryPoint': 'deploy_poison',\n",
      " 'entryPointKwargs': '-P run_id=c7d9ece4fa1d48f48863659a09243332 -P '\n",
      "                     'data_dir=/nfs/data/Mnist/training -P '\n",
      "                     'poison_deployment_method=replace',\n",
      " 'experimentId': 9,\n",
      " 'jobId': '7b5e0042-b7df-4099-8188-495e69dcd442',\n",
      " 'lastModified': '2020-12-10T08:25:14.127458',\n",
      " 'mlflowRunId': None,\n",
      " 'queueId': 1,\n",
      " 'status': 'queued',\n",
      " 'timeout': '24h',\n",
      " 'workflowUri': 's3://workflow/b94b86f7038e4b9e864dd674eb181ba1/workflows.tar.gz'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response_deploy_poison_le_net = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"deploy_poison\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P run_id={response_gen_poison_le_net['mlflowRunId']}\",\n",
    "            \"-P data_dir=/nfs/data/Mnist/training\",\n",
    "            \"-P poison_deployment_method=replace\",\n",
    "            #\"-P num_poisoned_images=100\",\n",
    "        ]\n",
    "    ),\n",
    "    queue=\"tensorflow_cpu\",\n",
    "    depends_on=response_gen_poison_le_net[\"jobId\"],\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Poison deployment (LeNet-5 architecture) job submitted\")\n",
    "print(\"\")\n",
    "pprint.pprint(response_deploy_poison_le_net)\n",
    "print(\"\")\n",
    "\n",
    "while mlflow_run_id_is_not_known(response_deploy_poison_le_net):\n",
    "    time.sleep(1)\n",
    "    response_deploy_poison_le_net = restapi_client.get_job_by_id(response_deploy_poison_le_net[\"jobId\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, train and retest poisoned dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poisoned training (LeNet-5 architecture) job submitted\n",
      "\n",
      "{'createdOn': '2020-12-10T08:25:18.254917',\n",
      " 'dependsOn': '7b5e0042-b7df-4099-8188-495e69dcd442',\n",
      " 'entryPoint': 'train',\n",
      " 'entryPointKwargs': '-P testing_dataset_run_id=None -P '\n",
      "                     'training_dataset_run_id=7801e4a8caee41d8b4597a531910a03a '\n",
      "                     '-P batch_size=256 -P register_model=True -P '\n",
      "                     'model_architecture=le_net -P '\n",
      "                     'model_tag=poisoned_runID_7801e4a8caee41d8b4597a531910a03a '\n",
      "                     '-P epochs=30 -P data_dir_train=/nfs/data/ -P '\n",
      "                     'data_dir_test=/nfs/data/Mnist/testing -P '\n",
      "                     'load_dataset_from_mlruns=True',\n",
      " 'experimentId': 9,\n",
      " 'jobId': 'fbb6ef38-231e-441a-afaf-fe8a04cd6fd6',\n",
      " 'lastModified': '2020-12-10T08:25:18.254917',\n",
      " 'mlflowRunId': None,\n",
      " 'queueId': 2,\n",
      " 'status': 'queued',\n",
      " 'timeout': '24h',\n",
      " 'workflowUri': 's3://workflow/8f41004988de44128fd0ef9ce3bf741b/workflows.tar.gz'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response_le_net_poison_mnist_training = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"train\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P testing_dataset_run_id=None\",\n",
    "            f\"-P training_dataset_run_id={response_deploy_poison_le_net['mlflowRunId']}\",\n",
    "            \"-P batch_size=256\",\n",
    "            \"-P register_model=True\",\n",
    "            \"-P model_architecture=le_net\",\n",
    "            f\"-P model_tag=poisoned_runID_{response_deploy_poison_le_net['mlflowRunId']}\",\n",
    "            \"-P epochs=30\",\n",
    "            \"-P data_dir_train=/nfs/data/\",\n",
    "            \"-P data_dir_test=/nfs/data/Mnist/testing\",\n",
    "            \"-P load_dataset_from_mlruns=True\",\n",
    "\n",
    "        ]\n",
    "    ),\n",
    "    \n",
    "    queue=\"tensorflow_gpu\",\n",
    "    depends_on=response_deploy_poison_le_net[\"jobId\"],\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Poisoned training (LeNet-5 architecture) job submitted\")\n",
    "print(\"\")\n",
    "pprint.pprint(response_le_net_poison_mnist_training)\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "while mlflow_run_id_is_not_known(response_le_net_poison_mnist_training):\n",
    "    time.sleep(1)\n",
    "    response_le_net_poison_mnist_training = restapi_client.get_job_by_id(response_le_net_poison_mnist_training[\"jobId\"])\n",
    "    \n",
    "# Wait for poisoned training to finish.\n",
    "while (response_le_net_poison_mnist_training['status'] != 'finished'):\n",
    "    time.sleep(1)\n",
    "    response_le_net_poison_mnist_training = restapi_client.get_job_by_id(response_le_net_poison_mnist_training[\"jobId\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check if the attack worked, the target image should be reclassified as beloning to the new target class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accessing MLflow Client Server. Downloading model files.\n",
      "{'Server': 'nginx/1.18.0 (Ubuntu)', 'Date': 'Thu, 10 Dec 2020 08:45:45 GMT', 'Content-Type': 'application/octet-stream', 'Content-Length': '14446376', 'Connection': 'keep-alive', 'Content-Disposition': 'attachment; filename=model.h5', 'Last-Modified': 'Thu, 10 Dec 2020 08:45:45 GMT', 'Cache-Control': 'public, max-age=43200', 'Expires': 'Thu, 10 Dec 2020 20:45:45 GMT', 'ETag': '\"1607589945.895891-14446376-3930983576\"'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hhuang/.conda/envs/tensorflow-mnist-classifier/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_util.py:523: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  tensor_proto.tensor_content = nparray.tostring()\n",
      "/home/hhuang/.conda/envs/tensorflow-mnist-classifier/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/data_structures.py:720: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  if not isinstance(wrapped_dict, collections.Mapping):\n",
      "/home/hhuang/.conda/envs/tensorflow-mnist-classifier/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:348: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  if not isinstance(values, collections.Sequence):\n"
     ]
    }
   ],
   "source": [
    "# Model download:\n",
    "import requests\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "def load_model_from_job_run(run_id, model_dir):\n",
    "    params = {\"path\":\"model/data/model.h5\", \"run_uuid\": run_id}\n",
    "    r = requests.get('http://localhost:35000/get-artifact', params=params)\n",
    "    print(\"Accessing MLflow Client Server. Downloading model files.\")\n",
    "    print(r.headers)\n",
    "    model_path = os.path.join(model_dir, 'model.h5')\n",
    "    \n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "        \n",
    "    with open(model_path, \"wb+\") as f:\n",
    "        f.write(r.content)\n",
    "    \n",
    "    return tf.keras.models.load_model(model_path)\n",
    "\n",
    "corrupt_model = load_model_from_job_run(response_le_net_poison_mnist_training['mlflowRunId'], './test_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Image label: 9\n",
      "Predicted label (corrupted model): 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hhuang/.conda/envs/tensorflow-mnist-classifier/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_util.py:523: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  tensor_proto.tensor_content = nparray.tostring()\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "target_image = f\"/nfs/1/datasets/Mnist/testing/{original_label}/{target_file}\"\n",
    "\n",
    "# load and show an image with Pillow\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "# Open the image form working directory\n",
    "image = Image.open(target_image)\n",
    "# summarize some details about the image\n",
    "print(\"Original Image label: \" + str(original_label) )\n",
    "print(\"Predicted label (corrupted model): \" + str(np.argmax(corrupt_model.predict(np.reshape(image, (1,28,28,1))), axis=1)[0]))\n",
    "image = np.asarray(image)\n",
    "\n",
    "# display the array of pixels as an image\n",
    "import matplotlib.pyplot as plt\n",
    "# plot the sample\n",
    "fig = plt.figure\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
